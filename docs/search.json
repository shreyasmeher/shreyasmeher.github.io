[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shreyas Meher - Researcher and PhD Candidate",
    "section": "",
    "text": "Welcome! I’m Shreyas Meher. This site showcases my work in computational linguistics and political analysis. Feel free to explore and connect with me!\n\n\nResearch Interests\n\nLarge Language Models (LLMs), Internet Censorship, Developmental Economics, Political Conflict and Violence\n\n\n\nCurrently at\n\nThe University of Texas at Dallas  Research Assistant  ConfliBERT Project with Dr. Patrick Brandt (2022-present)  Dr. Pengfei Zhang (2022-present)  Dr. Lauren Pinson (2021-present)  Dr. Jonas Bunte (2020-2021)\n\n\nTeaching Assistant  Dr. Vito D’Orazio (2020-2021)  Dr. Richard Scotch (2020)\n\n\n\nKey Projects\n\nConfliBERT Research Lab  A groundbreaking project exploring political conflict and violence using pre-trained language models. Learn More\n\n\nDissertation on Censorship in Democracies and Autocracies  An in-depth analysis focusing on electoral accountability with case studies in India and China. Read More"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Professionally\nI am a PhD Candidate in Public Policy & Political Economy at the University of Texas at Dallas. My research bridges the gap between political science and computational linguistics, focusing on areas such as global finance, economic development, and the impact of internet censorship in different political regimes. I have been actively involved in the ConfliBERT Research Lab with Dr. Patrick Brandt, contributing to the development of a language model for analyzing political conflict and violence. My upcoming dissertation examines censorship efforts across democracies and autocracies, with a focus on electoral accountability, employing methods like DID in India and synthetic control in China.\n\n\nPersonally\nI’m an avid football fan, rooting for Inter Milan, and a culinary enthusiast who loves exploring and creating new Dim Sum recipes.\n\n\nEducation\n\nNarsee Monjee Institute of Management Studies\nBsc Economics, 2016\n\n\nUniversity of Mumbai\nMa Public Policy, 2018\n\n\nThe University of Texas at Dallas\nMsc Management Sciences, 2020\n\n\nThe University of Texas at Dallas\nPhd Public Policy & Political Economy, Expected 2025"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Shreyas Meher",
    "section": "Education",
    "text": "Education\nUniversity of Texas at Dallas | Richardson, TX  PhD in Public Policy & Political Economy | Aug 2020 - May 2024\nUniversity of Texas at Dallas | Richardson, TX  Masters of Science in Management | Aug 2018 - May 2020"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Shreyas Meher",
    "section": "Experience",
    "text": "Experience\nThe University of Texas at Dallas | Research & Teaching Assistant | August 2020 - present"
  },
  {
    "objectID": "index.html#fa-hand-peace-hello-there-this-is-a-website-i-dont-always-have-a-chance-to-update-but-it-has-a-few-posts-and-some-ways-to-get-in-touch-with-me-if-you-need-to-cheers-fa-champagne-glasses",
    "href": "index.html#fa-hand-peace-hello-there-this-is-a-website-i-dont-always-have-a-chance-to-update-but-it-has-a-few-posts-and-some-ways-to-get-in-touch-with-me-if-you-need-to-cheers-fa-champagne-glasses",
    "title": "Shreyas Meher",
    "section": " hello there! this is a website I don’t always have a chance to update but it has a few posts and some ways to get in touch with me if you need to; cheers ",
    "text": "hello there! this is a website I don’t always have a chance to update but it has a few posts and some ways to get in touch with me if you need to; cheers"
  },
  {
    "objectID": "assignments/labs/Lab01.html",
    "href": "assignments/labs/Lab01.html",
    "title": "EPPS 6302: Lab Assignments",
    "section": "",
    "text": "x <- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix\n\nstarting httpd help server ... done\n\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=F) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9946764\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(5) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.03163502\n\nvar(y)\n\n[1] 0.8935626\n\nsqrt(var(y))\n\n[1] 0.9452844\n\nsd(y)\n\n[1] 0.9452844\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y, pch=20, col = \"purple\") # Scatterplot for two numeric variables by default\n\n\n\nplot(x,y, pch=20, col = \"purple\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"skyblue\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\npng \n  2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "assignments/labs/Lab01.html#indexing-data-using",
    "href": "assignments/labs/Lab01.html#indexing-data-using",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Indexing Data using []",
    "text": "Indexing Data using []\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A)\n\n[1] 4 4"
  },
  {
    "objectID": "assignments/labs/Lab01.html#loading-data-from-github",
    "href": "assignments/labs/Lab01.html#loading-data-from-github",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Loading Data from GitHub",
    "text": "Loading Data from GitHub\n\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\")\n# fix(Auto) # Starting the X11 R data editor\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\",header=T,na.strings=\"?\")\n# fix(Auto)\nAuto=read.csv(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.csv\",header=T,na.strings=\"?\")\n# fix(Auto)\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,]\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto)\n\n[1] 392   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\""
  },
  {
    "objectID": "assignments/labs/Lab01.html#load-data-from-islr-website",
    "href": "assignments/labs/Lab01.html#load-data-from-islr-website",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Load data from ISLR website",
    "text": "Load data from ISLR website\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9"
  },
  {
    "objectID": "assignments/labs/Lab01.html#additional-graphical-and-numerical-summaries",
    "href": "assignments/labs/Lab01.html#additional-graphical-and-numerical-summaries",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Additional Graphical and Numerical Summaries",
    "text": "Additional Graphical and Numerical Summaries\n\n# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\nhist(mpg)\n\n\n\nhist(mpg,col=2)\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\nplot(horsepower,mpg)\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60"
  },
  {
    "objectID": "assignments/labs/Lab01.html#linear-regression",
    "href": "assignments/labs/Lab01.html#linear-regression",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\nInstalling packages into 'C:/Users/Asus/Documents/R/win-library/4.1'\n(as 'lib' is unspecified)\n\n\npackage 'MASS' successfully unpacked and MD5 sums checked\npackage 'ISLR' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Asus\\AppData\\Local\\Temp\\Rtmp2rbXAY\\downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 34.55384    0.56263   61.41   <2e-16 ***\nlstat       -0.95005    0.03873  -24.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375"
  },
  {
    "objectID": "assignments/labs/Lab01.html#multiple-linear-regression",
    "href": "assignments/labs/Lab01.html#multiple-linear-regression",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 33.22276    0.73085  45.458  < 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  < 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  < 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  < 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: < 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)"
  },
  {
    "objectID": "assignments/labs/Lab01.html#non-linear-transformations-of-the-predictors",
    "href": "assignments/labs/Lab01.html#non-linear-transformations-of-the-predictors",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Non-linear Transformations of the Predictors",
    "text": "Non-linear Transformations of the Predictors\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.862007   0.872084   49.15   <2e-16 ***\nlstat       -2.332821   0.123803  -18.84   <2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(>F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       22.5328     0.2318  97.197  < 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  < 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  < 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: < 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -76.488      5.028  -15.21   <2e-16 ***\nlog(rm)       54.055      2.739   19.73   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "assignments/labs/Lab01.html#qualitative-predictors",
    "href": "assignments/labs/Lab01.html#qualitative-predictors",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Qualitative Predictors",
    "text": "Qualitative Predictors\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  < 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  < 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  < 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  < 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: < 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1"
  },
  {
    "objectID": "assignments/labs/Lab01.html#interaction-terms-including-interaction-and-single-effects",
    "href": "assignments/labs/Lab01.html#interaction-terms-including-interaction-and-single-effects",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Interaction Terms (including interaction and single effects)",
    "text": "Interaction Terms (including interaction and single effects)\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  < 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "labs/lab1/Lab01.html",
    "href": "labs/lab1/Lab01.html",
    "title": "EPPS 6302: Lab01",
    "section": "",
    "text": "x <- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix\n\nstarting httpd help server ... done\n\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=F) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9956564\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(5) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.03163502\n\nvar(y)\n\n[1] 0.8935626\n\nsqrt(var(y))\n\n[1] 0.9452844\n\nsd(y)\n\n[1] 0.9452844\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y, pch=20, col = \"purple\") # Scatterplot for two numeric variables by default\n\n\n\nplot(x,y, pch=20, col = \"purple\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"skyblue\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\npng \n  2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "labs/lab2/Lab02.html",
    "href": "labs/lab2/Lab02.html",
    "title": "EPPS 6323: Lab02",
    "section": "",
    "text": "(Adapted from ISLR Chapter 3 Lab: Introduction to R)\n\n\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A)\n\n[1] 4 4\n\n\n\n\n\n\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\")\n# fix(Auto) # Starting the X11 R data editor\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\",header=T,na.strings=\"?\")\n# fix(Auto)\nAuto=read.csv(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.csv\",header=T,na.strings=\"?\")\n# fix(Auto)\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,]\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto)\n\n[1] 392   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"        \n\n\n\n\n\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9\n\n\n\n\n\n\n# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\nhist(mpg)\n\n\n\nhist(mpg,col=2)\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\nplot(horsepower,mpg)\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60 \n\n\n\n\n\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\nInstalling packages into 'C:/Users/Asus/Documents/R/win-library/4.1'\n(as 'lib' is unspecified)\n\n\npackage 'MASS' successfully unpacked and MD5 sums checked\npackage 'ISLR' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Asus\\AppData\\Local\\Temp\\RtmpknA7wj\\downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 34.55384    0.56263   61.41   <2e-16 ***\nlstat       -0.95005    0.03873  -24.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375 \n\n\n\n\n\n\n\n\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 33.22276    0.73085  45.458  < 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  < 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  < 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  < 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: < 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)\n\n\n\n\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.862007   0.872084   49.15   <2e-16 ***\nlstat       -2.332821   0.123803  -18.84   <2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(>F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       22.5328     0.2318  97.197  < 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  < 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  < 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: < 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -76.488      5.028  -15.21   <2e-16 ***\nlog(rm)       54.055      2.739   19.73   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: < 2.2e-16\n\n\n\n\n\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  < 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  < 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  < 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  < 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: < 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1\n\n\n\n\n\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  < 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "labs/lab3/Lab03.html",
    "href": "labs/lab3/Lab03.html",
    "title": "EPPS 6323: Lab03",
    "section": "",
    "text": "R Programming (EDA)\n(Adapted from Stackoverflow examples) (Objectives: Use plotly, reshape packages, interactive visualization)\n\nlibrary(tidyverse)\nlibrary(plotly)\ndata(iris)\nattach(iris)\n# Generate plot on three quantitative variables\niris_plot <- plot_ly(iris,\n                     x = Sepal.Length,\n                     y = Sepal.Width,\n                     z = Petal.Length,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     size = 0.02)\niris_plot\n\n\n\n\n# Regression object\n\npetal_lm <- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,\n               data = iris)\nlibrary(reshape2)\n\n#load data\n\npetal_lm <- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,data = iris)\n\n# Setting resolution parameter\ngraph_reso <- 0.05\n\n#Setup Axis\naxis_x <- seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = graph_reso)\naxis_y <- seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = graph_reso)\n\n# Regression surface\n# Rearranging data for plotting\npetal_lm_surface <- expand.grid(Sepal.Length = axis_x,Sepal.Width = axis_y,KEEP.OUT.ATTRS = F)\npetal_lm_surface$Petal.Length <- predict.lm(petal_lm, newdata = petal_lm_surface)\npetal_lm_surface <- acast(petal_lm_surface, Sepal.Width ~ Sepal.Length, value.var = \"Petal.Length\")\nhcolors=c(\"orange\",\"blue\",\"green\")[iris$Species]\niris_plot <- plot_ly(iris,\n                     x = ~Sepal.Length,\n                     y = ~Sepal.Width,\n                     z = ~Petal.Length,\n                     text = Species,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     marker = list(color = hcolors),\n                     size=0.02)\n# Add surface\niris_plot <- add_trace(p = iris_plot,\n                       z = petal_lm_surface,\n                       x = axis_x,\n                       y = axis_y,\n                       type = \"surface\",mode = \"markers\",\n                       marker = list(color = hcolors))\niris_plot\n\n\n\n\n\n\n\nRegression object\n\npetal_lm <- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width, \n               data = iris)"
  },
  {
    "objectID": "assignments/labs/lab.html",
    "href": "assignments/labs/lab.html",
    "title": "EPPS 6302: Lab Assignments",
    "section": "",
    "text": "x <- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=F) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9964111\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(5) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.03163502\n\nvar(y)\n\n[1] 0.8935626\n\nsqrt(var(y))\n\n[1] 0.9452844\n\nsd(y)\n\n[1] 0.9452844\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y, pch=20, col = \"purple\") # Scatterplot for two numeric variables by default\n\n\n\nplot(x,y, pch=20, col = \"purple\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"skyblue\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\npng \n  2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "assignments/labs/lab.html#indexing-data-using",
    "href": "assignments/labs/lab.html#indexing-data-using",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Indexing Data using []",
    "text": "Indexing Data using []\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A)\n\n[1] 4 4"
  },
  {
    "objectID": "assignments/labs/lab.html#loading-data-from-github",
    "href": "assignments/labs/lab.html#loading-data-from-github",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Loading Data from GitHub",
    "text": "Loading Data from GitHub\n\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\")\n# fix(Auto) # Starting the X11 R data editor\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\",header=T,na.strings=\"?\")\n# fix(Auto)\nAuto=read.csv(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.csv\",header=T,na.strings=\"?\")\n# fix(Auto)\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,]\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto)\n\n[1] 392   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\""
  },
  {
    "objectID": "assignments/labs/lab.html#load-data-from-islr-website",
    "href": "assignments/labs/lab.html#load-data-from-islr-website",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Load data from ISLR website",
    "text": "Load data from ISLR website\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9"
  },
  {
    "objectID": "assignments/labs/lab.html#additional-graphical-and-numerical-summaries",
    "href": "assignments/labs/lab.html#additional-graphical-and-numerical-summaries",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Additional Graphical and Numerical Summaries",
    "text": "Additional Graphical and Numerical Summaries\n\n# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\nhist(mpg)\n\n\n\nhist(mpg,col=2)\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\nplot(horsepower,mpg)\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60"
  },
  {
    "objectID": "assignments/labs/lab.html#linear-regression",
    "href": "assignments/labs/lab.html#linear-regression",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\nInstalling packages into 'C:/Users/Asus/Documents/R/win-library/4.1'\n(as 'lib' is unspecified)\n\n\npackage 'MASS' successfully unpacked and MD5 sums checked\npackage 'ISLR' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Asus\\AppData\\Local\\Temp\\Rtmp0yK4P7\\downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 34.55384    0.56263   61.41   <2e-16 ***\nlstat       -0.95005    0.03873  -24.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375"
  },
  {
    "objectID": "assignments/labs/lab.html#multiple-linear-regression",
    "href": "assignments/labs/lab.html#multiple-linear-regression",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 33.22276    0.73085  45.458  < 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  < 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  < 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  < 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: < 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)"
  },
  {
    "objectID": "assignments/labs/lab.html#non-linear-transformations-of-the-predictors",
    "href": "assignments/labs/lab.html#non-linear-transformations-of-the-predictors",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Non-linear Transformations of the Predictors",
    "text": "Non-linear Transformations of the Predictors\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.862007   0.872084   49.15   <2e-16 ***\nlstat       -2.332821   0.123803  -18.84   <2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(>F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       22.5328     0.2318  97.197  < 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  < 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  < 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: < 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -76.488      5.028  -15.21   <2e-16 ***\nlog(rm)       54.055      2.739   19.73   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "assignments/labs/lab.html#qualitative-predictors",
    "href": "assignments/labs/lab.html#qualitative-predictors",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Qualitative Predictors",
    "text": "Qualitative Predictors\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  < 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  < 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  < 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  < 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: < 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1"
  },
  {
    "objectID": "assignments/labs/lab.html#interaction-terms-including-interaction-and-single-effects",
    "href": "assignments/labs/lab.html#interaction-terms-including-interaction-and-single-effects",
    "title": "EPPS 6302: Lab Assignments",
    "section": "Interaction Terms (including interaction and single effects)",
    "text": "Interaction Terms (including interaction and single effects)\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  < 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "assignments/a2/a2.html",
    "href": "assignments/a2/a2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "library(haven)\nlibrary(ggmice)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.2 --\nv tibble  3.1.8      v dplyr   1.0.10\nv tidyr   1.2.1      v stringr 1.4.1 \nv readr   2.1.3      v forcats 0.5.2 \nv purrr   0.3.5      \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(Ecdat)\n\nLoading required package: Ecfun\n\nAttaching package: 'Ecfun'\n\nThe following object is masked from 'package:base':\n\n    sign\n\n\nAttaching package: 'Ecdat'\n\nThe following object is masked from 'package:datasets':\n\n    Orange\n\nlibrary(dplyr)\nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\nlibrary(ggcorrplot)\nlibrary(naniar)\nlibrary(cli)\n\nTEDS_2016<-read_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")"
  },
  {
    "objectID": "assignments/a2/a2.html#missingness-plots",
    "href": "assignments/a2/a2.html#missingness-plots",
    "title": "Assignment 2",
    "section": "Missingness plots",
    "text": "Missingness plots\n\ncolSums(is.na(TEDS_2016)) / nrow(TEDS_2016)\n\n       District             Sex             Age             Edu           Arear \n     0.00000000      0.00000000      0.00000000      0.00000000      0.00000000 \n         Career         Career8          Ethnic           Party         PartyID \n     0.00000000      0.00000000      0.00000000      0.00000000      0.00000000 \n          Tondu          Tondu3             nI2        votetsai           green \n     0.00000000      0.00000000      0.00000000      0.25384615      0.00000000 \n    votetsai_nm    votetsai_all    Independence     Unification              sq \n     0.25384615      0.14674556      0.00000000      0.00000000      0.00000000 \n      Taiwanese             edu          female     whitecollar       lowincome \n     0.00000000      0.00591716      0.00000000      0.00000000      0.00000000 \n         income       income_nm             age             KMT             DPP \n     0.00000000      0.19526627      0.00000000      0.00000000      0.00000000 \n            npp         noparty             pfp           South           north \n     0.00000000      0.00000000      0.00000000      0.00000000      0.00000000 \n  Minnan_father Mainland_father      Econ_worse      Inequality     inequality5 \n     0.00000000      0.00000000      0.00000000      0.00000000      0.00000000 \n     econworse5 Govt_for_public        pubwelf5  Govt_dont_care      highincome \n     0.00000000      0.00000000      0.00000000      0.00000000      0.19526627 \n        votekmt      votekmt_nm            Blue           Green        No_Party \n     0.00000000      0.25384615      0.00000000      0.00000000      0.00000000 \n       voteblue     voteblue_nm       votedpp_1       votekmt_1 \n     0.00000000      0.25384615      0.11065089      0.11065089 \n\nplot_pattern(TEDS_2016)\n\n\n\nTEDS_2016 %>%\n  # Create an UpSet plot\n  gg_miss_upset(., nsets = 10)\n\n\n\ntable(TEDS_2016$Tondu)\n\n\n  1   2   3   4   5   6   9 \n 27 180 546 328 380 108 121"
  },
  {
    "objectID": "assignments/a2/a2.html#some-plots",
    "href": "assignments/a2/a2.html#some-plots",
    "title": "Assignment 2",
    "section": "Some plots",
    "text": "Some plots\n\nbarplot(table(TEDS_2016$Tondu))\n\n\n\ncounts <- table(TEDS_2016$Tondu, TEDS_2016$Sex)\nmosaicplot(counts, xlab='Tondu', ylab='Sex',main='Tondu by Sex', col='orange')"
  },
  {
    "objectID": "assignments/a2/a2.html#correlation-plots",
    "href": "assignments/a2/a2.html#correlation-plots",
    "title": "Assignment 2",
    "section": "Correlation plots",
    "text": "Correlation plots\n\nsel_dat<-TEDS_2016%>%select(Tondu,female, DPP, age, income, edu, Taiwanese, Econ_worse,votetsai)\n\ncormat <- sel_dat %>%\n  cor(., use = \"pairwise.complete.obs\")\n\ncorrplot(cormat, # correlation matrix\n         order = \"hclust\", # hierarchical clustering of correlations\n         addrect = 2) # number of rectangles to draw around clusters\n\n\n\nggcorrplot(cormat, # correlation matrix\n           type = \"lower\", # print the lower part of the correlation matrix\n           hc.order = TRUE, # hierarchical clustering of correlations\n           lab = TRUE) # add correlation values as labels"
  },
  {
    "objectID": "projects/BLScraper/bls.html",
    "href": "projects/BLScraper/bls.html",
    "title": "BLS Scraper Project",
    "section": "",
    "text": "Project Summary\nThe script is a .ipynb file named as Final.ipynb. Load the jupyter notebook with Jupyter Lab or Jupyter notebook.\nThe first few cells in the script ask the user to input the working url of the BLS content/table that they want to scrape using the script. Here, they are expected to input a url from https://www.bls.gov/bls/newsrels.htm#OPLC, after which the url is stored by the script.\nThe url is then scraped using BeautifulSoup, looking for the relevant tags of the various tables in the page. This script is unique in the sense that it allows for selective scraping of multiple tables in the webpage, which is not a base function of the packages used (Pandas or BeautifulSoup). Tables are first unwrapped from within the various tags and then merged using a loop function.\nThe user is then asked which of the tables in the page (in the case that there are multiple of them - eg. https://www.bls.gov/regions/southwest/news-release/2022/occupationalemploymentandwages_houston_20220624.htm) they want to scrape.\nTo clean the data up even more, the footnote markers are then removed from the dataframe using another function. As the data scraped is going to be quantitative in nature, $ signs and markers are removed from the dataframe created as well. This is to ensure that the data is readable by statistical software and requires very little cleaning after it is run through the script. You might have to change a few tags in the script for this to work, and so I have #’d out the commands to do the same.\nFinally, the user is then prompted once again to define a .csv filename for the data to be stored to in their local computing environment. The .csv file is then stored onto the working directory.\n\n#workspace init\nimport urllib\nimport pandas as pd\nfrom bs4 import BeautifulSoup\n\n#defining variables with user-input\n\ndef new_func():\n    url = input('Please enter the BLS publication that you want to scrape table from:')\n    return url\n\nurl = new_func()\ndata = urllib.request.urlopen(url).read()\n\nsp = BeautifulSoup(data,'html.parser')\n\n#Let us first get the table attributes on the BLS website\nprint('Table attributes')\nfor table in sp.find_all('table'):\n    print(table.get('class'))\n    break\n\nlsttb = sp.find('table',class_='regular')\n\n#check for multiple tables and unwrap them\n\nfor table in sp.findChildren(attrs={'id': 'regular'}): \n    for c in table.children:\n        if c.name in ['tbody', 'thead']:\n            c.unwrap()\n\n#dataset creation \n\ndata_pandas = pd.read_html(str(sp), flavor=\"bs4\",thousands=',',decimal='.')\n\n#clean dataset\ndf = pd.concat(data_pandas, axis=0)#to convert lists of pd.read_html to dataframe\n\n#export to csv\ndf.to_csv(input('Specify .csv filename:'))\n\nTable attributes\n['regular']"
  },
  {
    "objectID": "projects/AidData/Flows.html",
    "href": "projects/AidData/Flows.html",
    "title": "Shreyas Meher",
    "section": "",
    "text": "import numpy as np \nimport pandas as pd \nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport missingno\n#from floweaver import *\nimport plotly as py\n#from ipysankeywidget import SankeyWidget\nimport missingno\ninit_notebook_mode(connected=True)\n\nmaster = pd.read_csv('C:/Users/Asus/Box/PhD/SummerProj/Python/all_flow_classes.csv')\nms = master.copy() #working dataframe\n\n\nprint(ms.shape)\n\n(6190, 78)\n\n\n\nms.rename(columns = {'recipient_condensed':'country'}, inplace = True) \nms.rename(columns = {'transactions_start_year':'start_year'}, inplace = True) \nms['flow_class'] = ms['flow_class'].replace({'ODA-like': 'Aid', 'OOF-like': 'Non-Aid', 'Vague (Official Finance)': 'Not Sure'})\n\n\nmapbox_access_token  =  'pk.eyJ1IjoidW5rbGV0YW0iLCJhIjoiY2tkNnljemFxMG1mYTJ6cmE4bW1yYjczeiJ9.rBvwQf6Zw4BTA_f_O9dKbg'\nms  = ms.sort_values(by=['start_year'], ascending=True)\n\nms['Project'] = \" \"+ ms['project_title'] + \" [\" + ms['location_type_name']+ \"]\"\nfig = px.scatter_mapbox(ms, \n                     lon = ms['longitude'],\n                     lat = ms['latitude'],\n                     \n                     opacity = 0.5,\n                     color=\"flow_class\", \n                     hover_name=\"place_name\",\n                     animation_frame=\"start_year\",\n                     )\n\nfig.update_layout(\n    title = \"Investment from China [2000 - 2014]\",\n    legend_title_text='Investment Category', \n    hovermode='closest',\n    mapbox=dict(\n        \n        accesstoken=mapbox_access_token,\n        bearing=0,\n        pitch=0,\n        zoom=2,\n        style = \"light\"\n    )\n)\n#fig.show()\niplot(fig)\n\n\n                                                \n\n\n\nvalues = ms['flow_class'].value_counts()\nclass_ = pd.unique(ms['flow_class'])\n\nfig = px.pie(ms, values=values, labels=class_, names = class_)\nfig.update_layout(\n    \n    title = \"Total Investment - Category\",\n    legend_title_text='Investment Category',\n    showlegend=True\n    \n)\n\nfig.show()\n\n\n                                                \n\n\n\nvalues = ms['flow'].value_counts()\nclass_ = pd.unique(ms['flow'])\n\nfig = px.pie(ms, values=values, labels=class_, names = class_, hole=.7)\nfig.update_layout(\n    \n    title = \"Total Investment - Type\",\n    legend_title_text='Type of Investment',\n    showlegend=True\n    \n)\n\nfig.show()"
  },
  {
    "objectID": "projects/AidData/Flows.html#references",
    "href": "projects/AidData/Flows.html#references",
    "title": "Shreyas Meher",
    "section": "References",
    "text": "References\n\nTierney, Michael J., Daniel L. Nielson, Darren G. Hawkins, J. Timmons Roberts, Michael G. Findley, Ryan M. Powers, Bradley Parks, Sven E. Wilson, and Robert L. Hicks. 2011. More Dollars than Sense: Refining Our Knowledge of Development Finance Using AidData. World Development 39 (11): 1891-1906.\n\n\nStrandow, Daniel, Michael Findley, Daniel Nielson, and Joshua Powell. 2011. The UCDP-AidData codebook on Geo-referencing Foreign Aid. Version 1.1. Uppsala Conflict Data Program. Uppsala, Sweden: Uppsala University."
  },
  {
    "objectID": "assignments/a3/a3.html",
    "href": "assignments/a3/a3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "pacman::p_load(ggplot2, tidyr, dplyr, haven, gridExtra, ggExtra, RColorBrewer)\nTEDS_2016 <- read_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")\nTEDS_2016$Tondu<-as.numeric(TEDS_2016$Tondu,labels=c(\"Unificationnow”,“Statusquo,unif.infuture”,“Statusquo,decidelater\",\"Statusquoforever\",\"Statusquo,indep.infuture\",\"Independencenow”,“Noresponse\"))\nhead(TEDS_2016$Tondu)\n\n[1] 3 5 3 5 9 4\n\n\n\n\n\nsel_dat<-TEDS_2016%>%select(Tondu,female, DPP, age, income, edu, Taiwanese, Econ_worse,votetsai)\n\n\n\n\n\nfit1<-lm(Tondu~age+edu+income, data=sel_dat)\nsummary(fit1)\n\n\nCall:\nlm(formula = Tondu ~ age + edu + income, data = sel_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7780 -1.1841 -0.4322  1.1079  5.4157 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  5.302529   0.257369  20.603  < 2e-16 ***\nage         -0.004205   0.003194  -1.316   0.1882    \nedu         -0.244608   0.037579  -6.509 9.96e-11 ***\nincome      -0.031855   0.016357  -1.948   0.0516 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.725 on 1676 degrees of freedom\n  (10 observations deleted due to missingness)\nMultiple R-squared:  0.04287,   Adjusted R-squared:  0.04115 \nF-statistic: 25.02 on 3 and 1676 DF,  p-value: 7.771e-16\n\nta<-ggplot(sel_dat, aes(x=age,y=Tondu))+\n  geom_smooth(method = \"lm\", se = F, show.legend = F)+\n  geom_point(show.legend = F, position = \"jitter\",alpha=.5, pch=16) + ggthemes::theme_few() +\n  labs(x=\"Age\", y=\"TONDU preferences\")\n\nte<-ggplot(sel_dat, aes(x=edu,y=Tondu))+\n  geom_smooth(method = \"lm\", se = F, show.legend = F)+\n  geom_point(show.legend = F, position = \"jitter\",alpha=.5, pch=16) + ggthemes::theme_few() +\n  labs(x=\"Education\", y=\"TONDU preferences\")\n\nti<-ggplot(sel_dat, aes(x=income,y=Tondu))+\n  geom_smooth(method = \"lm\", se = F, show.legend = F)+\n  geom_point(show.legend = F, position = \"jitter\",alpha=.5, pch=16) + ggthemes::theme_few() +\n  labs(x=\"Income\", y=\"TONDU preferences\")\n\ngrid.arrange(ta,te,ti,ncol=3,nrow=1)\n\n\n\n\n\n\n\n\ntaei<-ggplot(sel_dat, aes(age, Tondu, colour=edu))+\n  geom_point()\n\nggMarginal(taei, type=\"histogram\")\n\n\n\n\n\n\n\nThe dependent variable has too many values, which we can find out using the unique() function. A multinomial logit would be better to use here, or other statistical methods to fit the model as linear regression is pretty weak here.\n\nunique(sel_dat$Tondu)\n\n[1] 3 5 9 4 6 2 1"
  },
  {
    "objectID": "assignments/proposal/prop-2-22-23.html",
    "href": "assignments/proposal/prop-2-22-23.html",
    "title": "Knowledge Mining Proposal",
    "section": "",
    "text": "Authors - Arslan Khalid, Kiwan Park, Shreyas Meher\n\n\nMedia Coverage of U.S. Foreign Policy\n\nArea/Topic\nThe news media often regards itself as the fourth branch of government. Some have referred to it as a watchdog that checks government access and holds elected officials accountable. However, research shows that media is influenced by a number of factors. Particularly, when reporting on foreign affairs the media is susceptible to “contesting government propaganda campaigns where the government can employ ideological weapons like anti-communism, a demonized enemy or alleged national security threats” (Herman, 1993). Research also shows that the media does not report on issues in an unbiased way. Some of the factors affecting media coverage that have been noted in research are:\n\nDominant media are themselves corporate elite establishment\nEconomic incentives of media companies\nStructural aspects of media, i.e. who owns the media companies\nIdeological bend of news organizations\n\nThis research looks to compare media outlets’ coverage and reporting of foreign policy issues in the United States. Our hypothesis is that media companies shift their coverage of foreign policy issues depending on which political party is in power.\n\n\n\nResearch Statement\nHow does the media’s coverage of U.S. foreign policy change with respect to which political party is in power? Specifically, this research will focus on the change in the President’s office after the 2016 election.\n\n\nMethods\nWe look to conduct a sentiment and network analysis of a large dataset. The dataset that we use is the All the News 2.0 dataset compiled by Andrew Thompson link to data. This dataset is useful for us as it contains text and publication data on a number of US news media websites such as Fox News, CNN, NYT, etc. along with essay websites such as Politico, New Yorker, etc. It will be interesting to see the number of clusters that we can form where we categorize these 27 American websites and conduct sentiment and network analysis for each one of this cluster to highlight differences and even similarities. Additionally, as we are required to add to the database, we look to use web scraping tools such as BeautifulSoup to further expand the dataset (possibly bring in news media from outside the U.S. such as Al Jazeera)."
  },
  {
    "objectID": "assignments/a4/a4.html",
    "href": "assignments/a4/a4.html",
    "title": "Assignment 4",
    "section": "",
    "text": "Foreign aid and migration are two closely intertwined topics that have gained significant attention in recent years. Foreign aid refers to the financial or material assistance provided by one country to another, typically with the aim of promoting economic, social, or political development in the recipient country. Migration, on the other hand, refers to the movement of people from one country to another, usually in search of better economic opportunities, political stability, or refuge from conflict or persecution.\nForeign aid can have both positive and negative effects on migration. On the one hand, aid can help to reduce poverty and create economic opportunities in recipient countries, which may discourage people from emigrating in search of better prospects. On the other hand, aid can also contribute to the creation of a dependent relationship between donor and recipient countries, which may perpetuate economic and political instability and ultimately drive people to migrate.\nMoreover, the impact of migration on recipient countries can also vary depending on the context. While migration can bring new skills, ideas, and resources to host countries, it can also pose challenges in terms of social integration, labor market competition, and cultural differences.\nOverall, the relationship between foreign aid and migration is complex and multifaceted, and requires careful consideration and analysis to understand its implications and potential solutions."
  },
  {
    "objectID": "assignments/a4/a4.html#data",
    "href": "assignments/a4/a4.html#data",
    "title": "Assignment 4",
    "section": "Data",
    "text": "Data\nThe World Development Indicators (WDI) package in R is a tool used to access and manipulate data from the World Bank’s World Development Indicators database. The package provides functions for downloading and extracting data on a wide range of indicators related to economic and social development, such as population, GDP, education, health, and poverty.\nThe WDI package in R allows users to easily retrieve data from the World Bank database in a format that is suitable for analysis and visualization. The package includes functions for filtering and aggregating data, as well as for merging data from multiple indicators and countries.\n\n\n[1] \"country\" \"year\"    \"migr\"    \"fa\"      \"inf\""
  },
  {
    "objectID": "assignments/a4/a4.html#scaling-all-of-the-data",
    "href": "assignments/a4/a4.html#scaling-all-of-the-data",
    "title": "Assignment 4",
    "section": "Scaling all of the data",
    "text": "Scaling all of the data\nScaling data before applying the k-means clustering algorithm is important because it helps to ensure that variables with larger scales or variances do not dominate the analysis.\nK-means clustering is a distance-based clustering algorithm, which means that it uses the Euclidean distance between variables to form clusters. If variables have different scales, those with larger scales or variances will have a greater impact on the distance calculation, and thus, the clustering outcome.\nBy scaling the data, we can ensure that each variable has a similar range of values and variance, which allows the k-means algorithm to equally weigh each variable in the clustering process. This can improve the accuracy and robustness of the clustering results.\nAdditionally, scaling the data can also help to improve the interpretability of the results. Since the variables are on the same scale, it is easier to compare the contributions of each variable to the cluster formation and to understand the relative importance of each variable in differentiating between the clusters."
  },
  {
    "objectID": "assignments/a4/a4.html#various-plots",
    "href": "assignments/a4/a4.html#various-plots",
    "title": "Assignment 4",
    "section": "Various plots",
    "text": "Various plots"
  },
  {
    "objectID": "assignments/a4/a4.html#hierarchical-clustering",
    "href": "assignments/a4/a4.html#hierarchical-clustering",
    "title": "Assignment 4",
    "section": "Hierarchical Clustering",
    "text": "Hierarchical Clustering"
  },
  {
    "objectID": "assignments/a4/a4.html#clustering-plots-figuring-out-optimum-cluster-number",
    "href": "assignments/a4/a4.html#clustering-plots-figuring-out-optimum-cluster-number",
    "title": "Assignment 4",
    "section": "Clustering plots & figuring out optimum cluster number",
    "text": "Clustering plots & figuring out optimum cluster number\n\n\nK-means clustering with 3 clusters of sizes 3, 33, 15\n\nCluster means:\n   mig_scale   fa_scale  inf_scale\n1 -2.9308285 -0.8960418  0.2749959\n2  0.1423792 -0.5373472 -0.3690791\n3  0.2729314  1.3613721  0.7569748\n\nClustering vector:\n [1] 2 2 2 2 2 2 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n[39] 3 3 3 3 3 3 3 3 3 3 3 3 3\n\nWithin cluster sum of squares by cluster:\n[1]  1.920832 34.173419 33.295700\n (between_SS / total_SS =  53.7 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\n\n\n\nFurther plots\n\n\n\n\n\n\n 1  2  3 \n 3 33 15 \n\n\n\n\n\n  cluster size ave.sil.width\n1       1   17          0.20\n2       2    5          0.12\n3       3   29          0.51"
  },
  {
    "objectID": "assignments/a4/a4.html#animated-clusterplot",
    "href": "assignments/a4/a4.html#animated-clusterplot",
    "title": "Assignment 4",
    "section": "Animated clusterplot",
    "text": "Animated clusterplot"
  },
  {
    "objectID": "projects/CPU/CPU.html",
    "href": "projects/CPU/CPU.html",
    "title": "CPU Usage",
    "section": "",
    "text": "Embedded Shiny application\nThis is a CPU usage widget that is created using shiny & python. Code edited from - https://quarto-ext.github.io/shinylive/.\n#| standalone: true\n#| components: [editor, viewer]\n## file: app.py\nimport sys\n\nif \"pyodide\" in sys.modules:\n    # psutil doesn't work on pyodide--use fake data instead\n    from fakepsutil import cpu_count, cpu_percent\n\n    shinylive_message = \"Note: the CPU data is simulated when running in Shinylive.\"\nelse:\n    from psutil import cpu_count, cpu_percent\n\n    shinylive_message = \"\"\n\nfrom math import ceil\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom shiny import App, Inputs, Outputs, Session, reactive, render, ui\n\n# The agg matplotlib backend seems to be a little more efficient than the default when\n# running on macOS, and also gives more consistent results across operating systems\nmatplotlib.use(\"agg\")\n\n# max number of samples to retain\nMAX_SAMPLES = 1000\n# secs between samples\nSAMPLE_PERIOD = 1\n\n\nncpu = cpu_count(logical=True)\n\napp_ui = ui.page_fluid(\n    ui.tags.style(\n        \"\"\"\n        /* Don't apply fade effect, it's constantly recalculating */\n        .recalculating {\n            opacity: 1;\n        }\n        tbody > tr:last-child {\n            /*border: 3px solid var(--bs-dark);*/\n            box-shadow:\n                0 0 2px 1px #fff, /* inner white */\n                0 0 4px 2px #0ff, /* middle cyan */\n                0 0 5px 3px #00f; /* outer blue */\n        }\n        #table table {\n            table-layout: fixed;\n            width: %s;\n            font-size: 0.8em;\n        }\n        th, td {\n            text-align: center;\n        }\n        \"\"\"\n        % f\"{ncpu*4}em\"\n    ),\n    ui.h3(\"CPU Usage %\", class_=\"mt-2\"),\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_select(\n                \"cmap\",\n                \"Colormap\",\n                {\n                    \"inferno\": \"inferno\",\n                    \"viridis\": \"viridis\",\n                    \"copper\": \"copper\",\n                    \"prism\": \"prism (not recommended)\",\n                },\n            ),\n            ui.p(ui.input_action_button(\"reset\", \"Clear history\", class_=\"btn-sm\")),\n            ui.input_switch(\"hold\", \"Freeze output\", value=False),\n            shinylive_message,\n            class_=\"mb-3\",\n        ),\n        ui.panel_main(\n            ui.div(\n                {\"class\": \"card mb-3\"},\n                ui.div(\n                    {\"class\": \"card-body\"},\n                    ui.h5({\"class\": \"card-title mt-0\"}, \"Graphs\"),\n                    ui.output_plot(\"plot\", height=f\"{ncpu * 40}px\"),\n                ),\n                ui.div(\n                    {\"class\": \"card-footer\"},\n                    ui.input_numeric(\"sample_count\", \"Number of samples per graph\", 50),\n                ),\n            ),\n            ui.div(\n                {\"class\": \"card\"},\n                ui.div(\n                    {\"class\": \"card-body\"},\n                    ui.h5({\"class\": \"card-title m-0\"}, \"Heatmap\"),\n                ),\n                ui.div(\n                    {\"class\": \"card-body overflow-auto pt-0\"},\n                    ui.output_table(\"table\"),\n                ),\n                ui.div(\n                    {\"class\": \"card-footer\"},\n                    ui.input_numeric(\"table_rows\", \"Rows to display\", 5),\n                ),\n            ),\n        ),\n    ),\n)\n\n\n@reactive.Calc\ndef cpu_current():\n    reactive.invalidate_later(SAMPLE_PERIOD)\n    return cpu_percent(percpu=True)\n\n\ndef server(input: Inputs, output: Outputs, session: Session):\n    cpu_history = reactive.Value(None)\n\n    @reactive.Calc\n    def cpu_history_with_hold():\n        # If \"hold\" is on, grab an isolated snapshot of cpu_history; if not, then do a\n        # regular read\n        if not input.hold():\n            return cpu_history()\n        else:\n            # Even if frozen, we still want to respond to input.reset()\n            input.reset()\n            with reactive.isolate():\n                return cpu_history()\n\n    @reactive.Effect\n    def collect_cpu_samples():\n        \"\"\"cpu_percent() reports just the current CPU usage sample; this Effect gathers\n        them up and stores them in the cpu_history reactive value, in a numpy 2D array\n        (rows are CPUs, columns are time).\"\"\"\n\n        new_data = np.vstack(cpu_current())\n        with reactive.isolate():\n            if cpu_history() is None:\n                cpu_history.set(new_data)\n            else:\n                combined_data = np.hstack([cpu_history(), new_data])\n                # Throw away extra data so we don't consume unbounded amounts of memory\n                if combined_data.shape[1] > MAX_SAMPLES:\n                    combined_data = combined_data[:, -MAX_SAMPLES:]\n                cpu_history.set(combined_data)\n\n    @reactive.Effect(priority=100)\n    @reactive.event(input.reset)\n    def reset_history():\n        cpu_history.set(None)\n\n    @output\n    @render.plot\n    def plot():\n        history = cpu_history_with_hold()\n\n        if history is None:\n            history = np.array([])\n            history.shape = (ncpu, 0)\n\n        nsamples = input.sample_count()\n\n        # Throw away samples too old to fit on the plot\n        if history.shape[1] > nsamples:\n            history = history[:, -nsamples:]\n\n        ncols = 2\n        nrows = int(ceil(ncpu / ncols))\n        fig, axeses = plt.subplots(\n            nrows=nrows,\n            ncols=ncols,\n            squeeze=False,\n        )\n        for i in range(0, ncols * nrows):\n            row = i // ncols\n            col = i % ncols\n            axes = axeses[row, col]\n            if i >= len(history):\n                axes.set_visible(False)\n                continue\n            data = history[i]\n            axes.yaxis.set_label_position(\"right\")\n            axes.yaxis.tick_right()\n            axes.set_xlim(-(nsamples - 1), 0)\n            axes.set_ylim(0, 100)\n\n            assert len(data) <= nsamples\n\n            # Set up an array of x-values that will right-align the data relative to the\n            # plotting area\n            x = np.arange(0, len(data))\n            x = np.flip(-x)\n\n            # Color bars by cmap\n            color = plt.get_cmap(input.cmap())(data / 100)\n            axes.bar(x, data, color=color, linewidth=0, width=1.0)\n\n            axes.set_yticks([25, 50, 75])\n            for ytl in axes.get_yticklabels():\n                if col == ncols - 1 or i == ncpu - 1 or True:\n                    ytl.set_fontsize(7)\n                else:\n                    ytl.set_visible(False)\n                    hide_ticks(axes.yaxis)\n            for xtl in axes.get_xticklabels():\n                xtl.set_visible(False)\n            hide_ticks(axes.xaxis)\n            axes.grid(True, linewidth=0.25)\n\n        return fig\n\n    @output\n    @render.table\n    def table():\n        history = cpu_history_with_hold()\n        latest = pd.DataFrame(history).transpose().tail(input.table_rows())\n        if latest.shape[0] == 0:\n            return latest\n        return (\n            latest.style.format(precision=0)\n            .hide(axis=\"index\")\n            .set_table_attributes(\n                'class=\"dataframe shiny-table table table-borderless font-monospace\"'\n            )\n            .background_gradient(cmap=input.cmap(), vmin=0, vmax=100)\n        )\n\n\ndef hide_ticks(axis):\n    for ticks in [axis.get_major_ticks(), axis.get_minor_ticks()]:\n        for tick in ticks:\n            tick.tick1line.set_visible(False)\n            tick.tick2line.set_visible(False)\n            tick.label1.set_visible(False)\n            tick.label2.set_visible(False)\n\n\napp = App(app_ui, server)\n\n\n\n## file: fakepsutil.py\n\n\"\"\"Generates synthetic data\"\"\"\n\nimport numpy as np\n\n\ndef cpu_count(logical: bool = True):\n    return 8 if logical else 4\n\n\nlast_sample = np.random.uniform(0, 100, size=cpu_count(True))\n\n\ndef cpu_percent(interval=None, percpu=False):\n    global last_sample\n    delta = np.random.normal(scale=10, size=len(last_sample))\n    last_sample = (last_sample + delta).clip(0, 100)\n    if percpu:\n        return last_sample.tolist()\n    else:\n        return last_sample.mean()\n    \n## file: requirements.txt\n    \n# Pandas needs Jinja2 for table styling, but it doesn't (yet) load automatically\n# in Pyodide, so we need to explicitly list it here.\nJinja2"
  },
  {
    "objectID": "assignments/a5/a5.html",
    "href": "assignments/a5/a5.html",
    "title": "Assignment 5",
    "section": "",
    "text": "The website at http://www.analytictech.com/mb021/mlk.htm provides access to the full text of the famous “I Have a Dream” speech delivered by Martin Luther King Jr. on August 28, 1963, during the March on Washington for Jobs and Freedom. The speech is widely considered to be one of the most important speeches of the 20th century, and has become a landmark moment in the American Civil Rights Movement.\nThe speech was delivered at the Lincoln Memorial in Washington D.C., and was attended by over 200,000 people. It called for an end to racial segregation and discrimination in the United States, and expressed a vision of a future where all people, regardless of their race or color, could live in harmony and equality.\nThe speech is notable for its powerful use of language and imagery, and its iconic closing lines in which Dr. King declared, “Free at last! Free at last! Thank God Almighty, we are free at last!”\nThe website provides the full text of the speech, as well as some background information on its historical context and significance. It is a valuable resource for anyone interested in the history of the American Civil Rights Movement or the art of public speaking."
  },
  {
    "objectID": "assignments/a5/a5.html#next-steps",
    "href": "assignments/a5/a5.html#next-steps",
    "title": "Assignment 5",
    "section": "Next steps",
    "text": "Next steps"
  },
  {
    "objectID": "assignments/a5/a5.html#coding",
    "href": "assignments/a5/a5.html#coding",
    "title": "Assignment 5",
    "section": "Coding",
    "text": "Coding\n\n\n[1] \"I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation. \"                                                                                                                                                                                                              \n[2] \"Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity. \"\n[3] \"But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination. \"                                                                                                                                                        \n\n\n[1] \"VectorSource\" \"SimpleSource\" \"Source\"      \n\n\n<<SimpleCorpus>>\nMetadata:  corpus specific: 1, document level (indexed): 0\nContent:  documents: 26\n\n [1] I am happy to join with you today in what will go down in\\r\\nhistory as the greatest demonstration for freedom in the history\\r\\nof our nation.                                                                                                                                                                                                                                                                                                                                                   \n [2] Five score years ago a great American in whose symbolic shadow\\r\\nwe stand today signed the Emancipation Proclamation. This\\r\\nmomentous decree came as a great beckoning light of hope to\\r\\nmillions of Negro slaves who had been seared in the flames of\\r\\nwithering injustice. It came as a joyous daybreak to end the long\\r\\nnight of their captivity.                                                                                                                                     \n [3] But one hundred years later the Negro is still not free. One\\r\\nhundred years later the life of the Negro is still sadly crippled\\r\\nby the manacles of segregation and the chains of discrimination.                                                                                                                                                                                                                                                                                             \n [4] One hundred years later the Negro lives on a lonely island of\\r\\npoverty in the midst of a vast ocean of material prosperity.                                                                                                                                                                                                                                                                                                                                                                     \n [5] One hundred years later the Negro is still languishing in the\\r\\ncomers of American society and finds himself in exile in his own\\r\\nland.                                                                                                                                                                                                                                                                                                                                                        \n [6] We all have come to this hallowed spot to remind America of\\r\\nthe fierce urgency of now. Now is the time to rise from the dark\\r\\nand desolate valley of segregation to the sunlit path of racial\\r\\njustice. Now is the time to change racial injustice to the solid\\r\\nrock of brotherhood. Now is the time to make justice ring out for\\r\\nall of God's children.                                                                                                                             \n [7] There will be neither rest nor tranquility in America until\\r\\nthe Negro is granted citizenship rights.                                                                                                                                                                                                                                                                                                                                                                                           \n [8] We must forever conduct our struggle on the high plane of\\r\\ndignity and discipline. We must not allow our creative protest to\\r\\ndegenerate into physical violence. Again and again we must rise\\r\\nto the majestic heights of meeting physical force with soul\\r\\nforce.                                                                                                                                                                                                                        \n [9] And the marvelous new militarism which has engulfed the Negro\\r\\ncommunity must not lead us to a distrust of all white people, for\\r\\nmany of our white brothers have evidenced by their presence here\\r\\ntoday that they have come to realize that their destiny is part\\r\\nof our destiny.                                                                                                                                                                                                      \n[10] So even though we face the difficulties of today and tomorrow\\r\\nI still have a dream. It is a dream deeply rooted in the American\\r\\ndream.                                                                                                                                                                                                                                                                                                                                                      \n[11] I have a dream that one day this nation will rise up and live\\r\\nout the true meaning of its creed: 'We hold these truths to be\\r\\nself-evident; that all men are created equal.\"                                                                                                                                                                                                                                                                                                                 \n[12] I have a dream that one day on the red hills of Georgia the\\r\\nsons of former slaves and the sons of former slave owners will be\\r\\nable to sit together at the table of brotherhood.                                                                                                                                                                                                                                                                                                             \n[13] I have a dream that one day even the state of Mississippi, a\\r\\nstate sweltering with the heat of injustice, sweltering with the\\r\\nheat of oppression, will be transformed into an oasis of freedom\\r\\nand justice.                                                                                                                                                                                                                                                                              \n[14] I have a dream that little children will one day live in a\\r\\nnation where they will not be judged by the color of their skin\\r\\nbut by the content of their character.                                                                                                                                                                                                                                                                                                                           \n[15] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[16] I have a dream that one day down in Alabama, with its vicious\\r\\nracists, with its Governor having his lips dripping with the\\r\\nwords of interposition and nullification, one day right there in\\r\\nAlabama little black boys and black girls will be able to join\\r\\nhands with little white boys and white girls as sisters and\\r\\nbrothers.                                                                                                                                                   \n[17] I have a dream today.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[18] I have a dream that one day every valley shall be exalted,\\r\\nevery hill and mountain shall be made low, the rough places\\r\\nplains, and the crooked places will be made straight, and before\\r\\nthe Lord will be revealed, and all flesh shall see it together.                                                                                                                                                                                                                                  \n[19] This is our hope. This is the faith that I go back to the\\r\\nmount with. With this faith we will be able to hew out of the\\r\\nmountain of despair a stone of hope. With this faith we will be\\r\\nable to transform the genuine discords of our nation into a\\r\\nbeautiful symphony of brotherhood. With this faith we will be\\r\\nable to work together, pray together; to struggle together, to go\\r\\nto jail together, to stand up for freedom forever, )mowing that\\r\\nwe will be free one day. \n[20] And I say to you today my friends, let freedom ring. From the\\r\\nprodigious hilltops of New Hampshire, let freedom ring. From the\\r\\nmighty mountains of New York, let freedom ring. From the mighty\\r\\nAlleghenies of Pennsylvania!                                                                                                                                                                                                                                                              \n[21] Let freedom ring from the snow capped Rockies of Colorado!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[22] Let freedom ring from the curvaceous slopes of California!                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[23] But not only there; let freedom ring from the Stone Mountain\\r\\nof Georgia!                                                                                                                                                                                                                                                                                                                                                                                                                       \n[24] Let freedom ring from Lookout Mountain in Tennessee!                                                                                                                                                                                                                                                                                                                                                                                                                                              \n[25] Let freedom ring from every hill and molehill in Mississippi.\\r\\nFrom every mountainside, let freedom ring.                                                                                                                                                                                                                                                                                                                                                                                       \n[26] And when this happens, when we allow freedom to ring, when we\\r\\nlet it ring from every village and hamlet, from every state and\\r\\nevery city, we will be able to speed up that day when all of\\r\\nGod's children, black men and white men, Jews and Gentiles,\\r\\nProtestants and Catholics, will be able to join hands and sing in\\r\\nthe words of the old Negro spiritual, \"Free at last! Free at\\r\\nlast! Thank God almighty, we're free at last!\"                                            \n\n\n<<TermDocumentMatrix (terms: 260, documents: 26)>>\nNon-/sparse entries: 383/6377\nSparsity           : 94%\nMaximal term length: 14\nWeighting          : term frequency (tf)\nSample             :\n         Docs\nTerms     16 18 19 2 20 26 3 6 8 9\n  able     1  0  3 0  0  2 0 0 0 0\n  day      2  1  1 0  0  1 0 0 0 0\n  dream    1  1  0 0  0  0 0 0 0 0\n  every    0  2  0 0  0  3 0 0 0 0\n  freedom  0  0  1 0  3  1 0 0 0 0\n  let      0  0  0 0  3  1 0 0 0 0\n  negro    0  0  0 1  0  1 2 0 0 1\n  one      2  1  1 0  0  0 2 0 0 0\n  ring     0  0  0 0  3  2 0 1 0 0\n  today    0  0  0 1  1  0 0 0 0 1\n\n\nfreedom     one    ring   dream     let     day \n     13      12      12      11      10       9"
  },
  {
    "objectID": "assignments/a6/a6.html",
    "href": "assignments/a6/a6.html",
    "title": "Assignment 6",
    "section": "",
    "text": "[1] \"District\"        \"Sex\"             \"Age\"             \"Edu\"            \n [5] \"Arear\"           \"Career\"          \"Career8\"         \"Ethnic\"         \n [9] \"Party\"           \"PartyID\"         \"Tondu\"           \"Tondu3\"         \n[13] \"nI2\"             \"votetsai\"        \"green\"           \"votetsai_nm\"    \n[17] \"votetsai_all\"    \"Independence\"    \"Unification\"     \"sq\"             \n[21] \"Taiwanese\"       \"edu\"             \"female\"          \"whitecollar\"    \n[25] \"lowincome\"       \"income\"          \"income_nm\"       \"age\"            \n[29] \"KMT\"             \"DPP\"             \"npp\"             \"noparty\"        \n[33] \"pfp\"             \"South\"           \"north\"           \"Minnan_father\"  \n[37] \"Mainland_father\" \"Econ_worse\"      \"Inequality\"      \"inequality5\"    \n[41] \"econworse5\"      \"Govt_for_public\" \"pubwelf5\"        \"Govt_dont_care\" \n[45] \"highincome\"      \"votekmt\"         \"votekmt_nm\"      \"Blue\"           \n[49] \"Green\"           \"No_Party\"        \"voteblue\"        \"voteblue_nm\"    \n[53] \"votedpp_1\"       \"votekmt_1\"      \n\n\n\nCall:\nglm(formula = votetsai ~ female, family = binomial, data = TEDS_2016)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4180  -1.3889   0.9546   0.9797   0.9797  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.54971    0.08245   6.667 2.61e-11 ***\nfemale      -0.06517    0.11644  -0.560    0.576    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1666.5  on 1260  degrees of freedom\nResidual deviance: 1666.2  on 1259  degrees of freedom\n  (429 observations deleted due to missingness)\nAIC: 1670.2\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "assignments/a6/a6.html#trying-out-for-taiwan-data",
    "href": "assignments/a6/a6.html#trying-out-for-taiwan-data",
    "title": "Assignment 6",
    "section": "Trying out for Taiwan data",
    "text": "Trying out for Taiwan data\n\n\n [1] \"District\"        \"Sex\"             \"Age\"             \"Edu\"            \n [5] \"Arear\"           \"Career\"          \"Career8\"         \"Ethnic\"         \n [9] \"Party\"           \"PartyID\"         \"Tondu\"           \"Tondu3\"         \n[13] \"nI2\"             \"votetsai\"        \"green\"           \"votetsai_nm\"    \n[17] \"votetsai_all\"    \"Independence\"    \"Unification\"     \"sq\"             \n[21] \"Taiwanese\"       \"edu\"             \"female\"          \"whitecollar\"    \n[25] \"lowincome\"       \"income\"          \"income_nm\"       \"age\"            \n[29] \"KMT\"             \"DPP\"             \"npp\"             \"noparty\"        \n[33] \"pfp\"             \"South\"           \"north\"           \"Minnan_father\"  \n[37] \"Mainland_father\" \"Econ_worse\"      \"Inequality\"      \"inequality5\"    \n[41] \"econworse5\"      \"Govt_for_public\" \"pubwelf5\"        \"Govt_dont_care\" \n[45] \"highincome\"      \"votekmt\"         \"votekmt_nm\"      \"Blue\"           \n[49] \"Green\"           \"No_Party\"        \"voteblue\"        \"voteblue_nm\"    \n[53] \"votedpp_1\"       \"votekmt_1\"      \n\n\n\nCall:\nglm(formula = votetsai ~ female, family = binomial, data = TEDS_2016)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4180  -1.3889   0.9546   0.9797   0.9797  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.54971    0.08245   6.667 2.61e-11 ***\nfemale      -0.06517    0.11644  -0.560    0.576    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1666.5  on 1260  degrees of freedom\nResidual deviance: 1666.2  on 1259  degrees of freedom\n  (429 observations deleted due to missingness)\nAIC: 1670.2\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "assignments/a6/a6.html#interpreting-the-first-logistic-regression-model",
    "href": "assignments/a6/a6.html#interpreting-the-first-logistic-regression-model",
    "title": "Assignment 6",
    "section": "Interpreting the first logistic regression model",
    "text": "Interpreting the first logistic regression model\nBased on the output of the logistic regression model, the coefficient for the female variable is -0.06517, and the p-value is 0.576. Since the p-value is greater than the standard significance level of 0.05, we fail to reject the null hypothesis, and there is no evidence to suggest that female voters are more likely to vote for President Tsai than male voters in this model.\nThe intercept of the model is 0.54971, which represents the log-odds of votetsai (voting for Tsai Ing-wen) for the reference group (male voters) in this case. The negative coefficient for the female variable (-0.06517) indicates that the log-odds of votetsai for female voters are slightly lower than for male voters, but this difference is not statistically significant.\nIt is essential to note that this model only includes the female predictor variable. Adding more variables (e.g., party ID, demographics, or issue-specific variables) may improve the model and provide more insights into factors affecting voting for President Tsai, which is what the next section will attempt to do.\n\n\n\nCall:\nglm(formula = votetsai ~ female + KMT + DPP + age + edu + income, \n    family = binomial, data = TEDS_2016)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7360  -0.3673   0.2408   0.2946   2.5408  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.618640   0.592084   2.734  0.00626 ** \nfemale       0.047406   0.177403   0.267  0.78930    \nKMT         -3.156273   0.250360 -12.607  < 2e-16 ***\nDPP          2.888943   0.267968  10.781  < 2e-16 ***\nage         -0.011808   0.007164  -1.648  0.09931 .  \nedu         -0.184604   0.083102  -2.221  0.02632 *  \nincome       0.013727   0.034382   0.399  0.68971    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1661.76  on 1256  degrees of freedom\nResidual deviance:  836.15  on 1250  degrees of freedom\n  (433 observations deleted due to missingness)\nAIC: 850.15\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "assignments/a6/a6.html#interpretation-for-the-updated-model",
    "href": "assignments/a6/a6.html#interpretation-for-the-updated-model",
    "title": "Assignment 6",
    "section": "Interpretation for the updated model",
    "text": "Interpretation for the updated model\nBased on the output of the logistic regression model with additional predictors, here is the interpretation of the results:\nFemale: The coefficient for the female variable is 0.047406 with a p-value of 0.78930. The p-value is greater than 0.05, so the effect of the female variable is not statistically significant. This means that there is no evidence to suggest that female voters are more likely to vote for President Tsai compared to male voters, after controlling for other variables.\nKMT: The coefficient for the KMT variable is -3.156273 with a p-value close to 0 (p < 2e-16). This indicates that respondents with a stronger KMT party affiliation are significantly less likely to vote for President Tsai.\nDPP: The coefficient for the DPP variable is 2.888943 with a p-value close to 0 (p < 2e-16). This suggests that respondents with a stronger DPP party affiliation are significantly more likely to vote for President Tsai.\nAge: The coefficient for the age variable is -0.011808 with a p-value of 0.09931. The p-value is slightly greater than 0.05, so the effect of age is not statistically significant at the 0.05 level. However, the negative coefficient suggests that older respondents are somewhat less likely to vote for President Tsai, but this relationship is weak.\nEdu: The coefficient for the edu variable is -0.184604 with a p-value of 0.02632. The negative coefficient indicates that respondents with higher education levels are more likely to vote for President Tsai, and this effect is statistically significant (p < 0.05).\nIncome: The coefficient for the income variable is 0.013727 with a p-value of 0.68971. The p-value is greater than 0.05, so the effect of income is not statistically significant. This means that there is no evidence to suggest that income levels significantly influence the likelihood of voting for President Tsai.\nIn summary, the most significant predictors in this model are KMT and DPP party affiliations, which have strong and statistically significant effects on the likelihood of voting for President Tsai. Education also has a significant effect, while the female, age, and income variables are not statistically significant in this model."
  },
  {
    "objectID": "assignments/a6/a6.html#coefficient-plots-for-the-two-models",
    "href": "assignments/a6/a6.html#coefficient-plots-for-the-two-models",
    "title": "Assignment 6",
    "section": "Coefficient plots for the two models",
    "text": "Coefficient plots for the two models\n\n\n\n\n\n\n\n\n\n\nStart:  AIC=793.13\nvotetsai ~ female + KMT + DPP + age + edu + income + Independence + \n    Econ_worse + Govt_dont_care + Minnan_father + Mainland_father + \n    Taiwanese\n\n                  Df Deviance    AIC\n- Govt_dont_care   1   767.14 791.14\n- age              1   767.31 791.31\n- female           1   767.40 791.40\n- income           1   767.49 791.49\n- Minnan_father    1   768.09 792.09\n- edu              1   768.18 792.18\n<none>                 767.13 793.13\n- Econ_worse       1   769.82 793.82\n- Mainland_father  1   774.99 798.99\n- Independence     1   784.68 808.68\n- Taiwanese        1   787.92 811.92\n- DPP              1   884.02 908.02\n- KMT              1   954.40 978.40\n\nStep:  AIC=791.14\nvotetsai ~ female + KMT + DPP + age + edu + income + Independence + \n    Econ_worse + Minnan_father + Mainland_father + Taiwanese\n\n                  Df Deviance    AIC\n- age              1   767.32 789.32\n- female           1   767.40 789.40\n- income           1   767.49 789.49\n- Minnan_father    1   768.11 790.11\n- edu              1   768.18 790.18\n<none>                 767.14 791.14\n- Econ_worse       1   769.84 791.84\n+ Govt_dont_care   1   767.13 793.13\n- Mainland_father  1   775.08 797.08\n- Independence     1   784.68 806.68\n- Taiwanese        1   787.92 809.92\n- DPP              1   884.68 906.68\n- KMT              1   954.41 976.41\n\nStep:  AIC=789.32\nvotetsai ~ female + KMT + DPP + edu + income + Independence + \n    Econ_worse + Minnan_father + Mainland_father + Taiwanese\n\n                  Df Deviance    AIC\n- female           1   767.59 787.59\n- income           1   767.70 787.70\n- Minnan_father    1   768.21 788.21\n<none>                 767.32 789.32\n- Econ_worse       1   770.11 790.11\n- edu              1   770.33 790.33\n+ age              1   767.14 791.14\n+ Govt_dont_care   1   767.31 791.31\n- Mainland_father  1   775.09 795.09\n- Independence     1   784.72 804.72\n- Taiwanese        1   787.93 807.93\n- DPP              1   885.39 905.39\n- KMT              1   954.61 974.61\n\nStep:  AIC=787.59\nvotetsai ~ KMT + DPP + edu + income + Independence + Econ_worse + \n    Minnan_father + Mainland_father + Taiwanese\n\n                  Df Deviance    AIC\n- income           1   767.95 785.95\n- Minnan_father    1   768.49 786.49\n<none>                 767.59 787.59\n- edu              1   770.43 788.43\n- Econ_worse       1   770.44 788.44\n+ female           1   767.32 789.32\n+ age              1   767.40 789.40\n+ Govt_dont_care   1   767.58 789.58\n- Mainland_father  1   775.21 793.21\n- Independence     1   785.27 803.27\n- Taiwanese        1   787.94 805.94\n- DPP              1   886.58 904.58\n- KMT              1   955.77 973.77\n\nStep:  AIC=785.95\nvotetsai ~ KMT + DPP + edu + Independence + Econ_worse + Minnan_father + \n    Mainland_father + Taiwanese\n\n                  Df Deviance    AIC\n- Minnan_father    1   768.87 784.87\n<none>                 767.95 785.95\n- edu              1   770.43 786.43\n- Econ_worse       1   770.69 786.69\n+ income           1   767.59 787.59\n+ female           1   767.70 787.70\n+ age              1   767.74 787.74\n+ Govt_dont_care   1   767.95 787.95\n- Mainland_father  1   775.59 791.59\n- Independence     1   785.62 801.62\n- Taiwanese        1   788.14 804.14\n- DPP              1   888.19 904.19\n- KMT              1   956.43 972.43\n\nStep:  AIC=784.87\nvotetsai ~ KMT + DPP + edu + Independence + Econ_worse + Mainland_father + \n    Taiwanese\n\n                  Df Deviance    AIC\n<none>                 768.87 784.87\n- Econ_worse       1   771.48 785.48\n- edu              1   771.59 785.59\n+ Minnan_father    1   767.95 785.95\n+ income           1   768.49 786.49\n+ female           1   768.61 786.61\n+ age              1   768.74 786.74\n+ Govt_dont_care   1   768.86 786.86\n- Mainland_father  1   775.96 789.96\n- Independence     1   786.35 800.35\n- Taiwanese        1   788.59 802.59\n- DPP              1   888.66 902.66\n- KMT              1   956.56 970.56\n\n\n\nCall:\nglm(formula = votetsai ~ KMT + DPP + edu + Independence + Econ_worse + \n    Mainland_father + Taiwanese, family = binomial, data = TEDS_2016)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.0043  -0.3074   0.1731   0.4096   2.7622  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)      0.05688    0.27971   0.203  0.83886    \nKMT             -2.88317    0.25561 -11.280  < 2e-16 ***\nDPP              2.47837    0.27407   9.043  < 2e-16 ***\nedu             -0.10296    0.06257  -1.645  0.09989 .  \nIndependence     1.00339    0.24761   4.052 5.07e-05 ***\nEcon_worse       0.30187    0.18640   1.619  0.10535    \nMainland_father -0.85644    0.33052  -2.591  0.00956 ** \nTaiwanese        0.86729    0.19455   4.458 8.28e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1661.76  on 1256  degrees of freedom\nResidual deviance:  768.87  on 1249  degrees of freedom\n  (433 observations deleted due to missingness)\nAIC: 784.87\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "assignments/a6/a6.html#interpreting-the-best-model",
    "href": "assignments/a6/a6.html#interpreting-the-best-model",
    "title": "Assignment 6",
    "section": "Interpreting the best model",
    "text": "Interpreting the best model\nThis is the best model selected by stepAIC based on AIC criteria. The model predicts the likelihood of voting for Tsai Ing-wen (votetsai) using the following predictors: KMT, DPP, edu, Independence, Econ_worse, Mainland_father, and Taiwanese.\nHere’s the interpretation of the model:\nKMT (Kuomintang) Party ID: The coefficient is -2.88317, and it is highly significant (p < 2e-16). A one-unit increase in KMT affiliation is associated with a decrease in the log-odds of voting for Tsai Ing-wen by 2.88317 units, holding other variables constant. In other words, KMT supporters are less likely to vote for Tsai Ing-wen.\nDPP (Democratic Progressive Party) Party ID: The coefficient is 2.47837, and it is highly significant (p < 2e-16). A one-unit increase in DPP affiliation is associated with an increase in the log-odds of voting for Tsai Ing-wen by 2.47837 units, holding other variables constant. DPP supporters are more likely to vote for Tsai Ing-wen.\nEducation (edu): The coefficient is -0.10296, and it is marginally significant (p = 0.09989). A one-unit increase in education level is associated with a decrease in the log-odds of voting for Tsai Ing-wen by 0.10296 units, holding other variables constant. More educated individuals are slightly less likely to vote for Tsai Ing-wen.\nIndependence: The coefficient is 1.00339, and it is highly significant (p = 5.07e-05). A one-unit increase in support for Taiwan’s independence is associated with an increase in the log-odds of voting for Tsai Ing-wen by 1.00339 units, holding other variables constant. Those who support Taiwan’s independence are more likely to vote for Tsai Ing-wen.\nEconomic evaluation (Econ_worse): The coefficient is 0.30187, and it is not significant (p = 0.10535). A one-unit increase in negative economic evaluation is associated with an increase in the log-odds of voting for Tsai Ing-wen by 0.30187 units, holding other variables constant. However, this effect is not statistically significant.\nMainland father (Mainland_father): The coefficient is -0.85644, and it is significant (p = 0.00956). A one-unit increase in being a descendent of mainland China is associated with a decrease in the log-odds of voting for Tsai Ing-wen by 0.85644 units, holding other variables constant. Individuals with mainland Chinese ancestry are less likely to vote for Tsai Ing-wen.\nSelf-identified Taiwanese (Taiwanese): The coefficient is 0.86729, and it is highly significant (p = 8.28e-06). A one-unit increase in self-identification as Taiwanese is associated with an increase in the log-odds of voting for Tsai Ing-wen by 0.86729 units, holding other variables constant. Self-identified Taiwanese are more likely to vote for Tsai Ing-wen.\nThe model has an AIC of 784.87, and the residual deviance is 768.87 on 1249 degrees of freedom. This model provides a better fit compared"
  },
  {
    "objectID": "assignments/a6/a6.html#lab-assignment",
    "href": "assignments/a6/a6.html#lab-assignment",
    "title": "Assignment 6",
    "section": "Lab Assignment",
    "text": "Lab Assignment\n\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n\n\nCall:\nlm(formula = medv ~ lstat, data = Boston)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\n\n\nCall:\nlm(formula = medv ~ lstat, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 34.55384    0.56263   61.41   <2e-16 ***\nlstat       -0.95005    0.03873  -24.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16\n\n\n\n\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\n\n       fit      lwr      upr\n1 34.55384 33.44846 35.65922\n2 29.80359 29.00741 30.59978\n3 25.05335 24.47413 25.63256\n4 20.30310 19.73159 20.87461\n\n\n       fit       lwr      upr\n1 34.55384 22.291923 46.81576\n2 29.80359 17.565675 42.04151\n3 25.05335 12.827626 37.27907\n4 20.30310  8.077742 32.52846\n\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 33.22276    0.73085  45.458  < 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  < 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: < 2.2e-16\n\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  < 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16\n\n\n\n\n\n\nCall:\nlm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n    tax + ptratio + black + lstat, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5984  -2.7386  -0.5046   1.7273  26.2373 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  36.341145   5.067492   7.171 2.73e-12 ***\ncrim         -0.108413   0.032779  -3.307 0.001010 ** \nzn            0.045845   0.013523   3.390 0.000754 ***\nchas          2.718716   0.854240   3.183 0.001551 ** \nnox         -17.376023   3.535243  -4.915 1.21e-06 ***\nrm            3.801579   0.406316   9.356  < 2e-16 ***\ndis          -1.492711   0.185731  -8.037 6.84e-15 ***\nrad           0.299608   0.063402   4.726 3.00e-06 ***\ntax          -0.011778   0.003372  -3.493 0.000521 ***\nptratio      -0.946525   0.129066  -7.334 9.24e-13 ***\nblack         0.009291   0.002674   3.475 0.000557 ***\nlstat        -0.522553   0.047424 -11.019  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.736 on 494 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7348 \nF-statistic: 128.2 on 11 and 494 DF,  p-value: < 2.2e-16\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  < 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: < 2.2e-16\n\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2), data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.862007   0.872084   49.15   <2e-16 ***\nlstat       -2.332821   0.123803  -18.84   <2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: < 2.2e-16\n\n\n\n\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\n\n     Sales          CompPrice       Income        Advertising    \n Min.   : 0.000   Min.   : 77   Min.   : 21.00   Min.   : 0.000  \n 1st Qu.: 5.390   1st Qu.:115   1st Qu.: 42.75   1st Qu.: 0.000  \n Median : 7.490   Median :125   Median : 69.00   Median : 5.000  \n Mean   : 7.496   Mean   :125   Mean   : 68.66   Mean   : 6.635  \n 3rd Qu.: 9.320   3rd Qu.:135   3rd Qu.: 91.00   3rd Qu.:12.000  \n Max.   :16.270   Max.   :175   Max.   :120.00   Max.   :29.000  \n   Population        Price        ShelveLoc        Age          Education   \n Min.   : 10.0   Min.   : 24.0   Bad   : 96   Min.   :25.00   Min.   :10.0  \n 1st Qu.:139.0   1st Qu.:100.0   Good  : 85   1st Qu.:39.75   1st Qu.:12.0  \n Median :272.0   Median :117.0   Medium:219   Median :54.50   Median :14.0  \n Mean   :264.8   Mean   :115.8                Mean   :53.32   Mean   :13.9  \n 3rd Qu.:398.5   3rd Qu.:131.0                3rd Qu.:66.00   3rd Qu.:16.0  \n Max.   :509.0   Max.   :191.0                Max.   :80.00   Max.   :18.0  \n Urban       US     \n No :118   No :142  \n Yes:282   Yes:258  \n                    \n                    \n                    \n                    \n\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Age:Price, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  < 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  < 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  < 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  < 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: < 2.2e-16\n\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1"
  },
  {
    "objectID": "assignments/a8/a8.html#generate-response-vector-𝑦-and-plot-x-and-y",
    "href": "assignments/a8/a8.html#generate-response-vector-𝑦-and-plot-x-and-y",
    "title": "Assignment 8",
    "section": "Generate response vector 𝑦 and plot x and y:",
    "text": "Generate response vector 𝑦 and plot x and y:"
  },
  {
    "objectID": "assignments/a8/a8.html#load-the-leaps-package-and-use-the-regsubsets-function",
    "href": "assignments/a8/a8.html#load-the-leaps-package-and-use-the-regsubsets-function",
    "title": "Assignment 8",
    "section": "Load the leaps package and use the regsubsets() function:",
    "text": "Load the leaps package and use the regsubsets() function:\n\n\nSubset selection object\nCall: regsubsets.formula(y ~ poly(X, 10, raw = T), data = data.frame(y, \n    X), nvmax = 10)\n10 Variables  (and intercept)\n                       Forced in Forced out\npoly(X, 10, raw = T)1      FALSE      FALSE\npoly(X, 10, raw = T)2      FALSE      FALSE\npoly(X, 10, raw = T)3      FALSE      FALSE\npoly(X, 10, raw = T)4      FALSE      FALSE\npoly(X, 10, raw = T)5      FALSE      FALSE\npoly(X, 10, raw = T)6      FALSE      FALSE\npoly(X, 10, raw = T)7      FALSE      FALSE\npoly(X, 10, raw = T)8      FALSE      FALSE\npoly(X, 10, raw = T)9      FALSE      FALSE\npoly(X, 10, raw = T)10     FALSE      FALSE\n1 subsets of each size up to 10\nSelection Algorithm: exhaustive\n          poly(X, 10, raw = T)1 poly(X, 10, raw = T)2 poly(X, 10, raw = T)3\n1  ( 1 )  \"*\"                   \" \"                   \" \"                  \n2  ( 1 )  \"*\"                   \" \"                   \" \"                  \n3  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n4  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n5  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n6  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n7  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n8  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n9  ( 1 )  \"*\"                   \"*\"                   \" \"                  \n10  ( 1 ) \"*\"                   \"*\"                   \"*\"                  \n          poly(X, 10, raw = T)4 poly(X, 10, raw = T)5 poly(X, 10, raw = T)6\n1  ( 1 )  \" \"                   \" \"                   \" \"                  \n2  ( 1 )  \"*\"                   \" \"                   \" \"                  \n3  ( 1 )  \" \"                   \" \"                   \" \"                  \n4  ( 1 )  \" \"                   \"*\"                   \" \"                  \n5  ( 1 )  \" \"                   \"*\"                   \"*\"                  \n6  ( 1 )  \" \"                   \" \"                   \" \"                  \n7  ( 1 )  \" \"                   \"*\"                   \"*\"                  \n8  ( 1 )  \"*\"                   \" \"                   \"*\"                  \n9  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n10  ( 1 ) \"*\"                   \"*\"                   \"*\"                  \n          poly(X, 10, raw = T)7 poly(X, 10, raw = T)8 poly(X, 10, raw = T)9\n1  ( 1 )  \" \"                   \" \"                   \" \"                  \n2  ( 1 )  \" \"                   \" \"                   \" \"                  \n3  ( 1 )  \" \"                   \" \"                   \" \"                  \n4  ( 1 )  \" \"                   \" \"                   \" \"                  \n5  ( 1 )  \" \"                   \" \"                   \" \"                  \n6  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n7  ( 1 )  \" \"                   \"*\"                   \" \"                  \n8  ( 1 )  \" \"                   \"*\"                   \"*\"                  \n9  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n10  ( 1 ) \"*\"                   \"*\"                   \"*\"                  \n          poly(X, 10, raw = T)10\n1  ( 1 )  \" \"                   \n2  ( 1 )  \" \"                   \n3  ( 1 )  \" \"                   \n4  ( 1 )  \" \"                   \n5  ( 1 )  \" \"                   \n6  ( 1 )  \" \"                   \n7  ( 1 )  \"*\"                   \n8  ( 1 )  \"*\"                   \n9  ( 1 )  \"*\"                   \n10  ( 1 ) \"*\""
  },
  {
    "objectID": "assignments/a8/a8.html#find-the-best-model-according-to-cp-bic-and-adjusted-r2-and-report-the-coefficients-of-the-best-model",
    "href": "assignments/a8/a8.html#find-the-best-model-according-to-cp-bic-and-adjusted-r2-and-report-the-coefficients-of-the-best-model",
    "title": "Assignment 8",
    "section": "Find the best model according to Cp, BIC, and adjusted R2, and report the coefficients of the best model:",
    "text": "Find the best model according to Cp, BIC, and adjusted R2, and report the coefficients of the best model:\n\n\nBest Model (Cp): 4 \n\n\nBest Model (BIC): 3 \n\n\nBest Model (Adjusted R2): 4 \n\n\n          (Intercept) poly(X, 10, raw = T)1 poly(X, 10, raw = T)2 \n             4.061507              8.975280              1.876209 \npoly(X, 10, raw = T)3 \n             1.017639"
  },
  {
    "objectID": "assignments/a8/a8.html#repeat-step-3-using-forward-stepwise-selection-and-backward-stepwise-selection-and-compare-the-results",
    "href": "assignments/a8/a8.html#repeat-step-3-using-forward-stepwise-selection-and-backward-stepwise-selection-and-compare-the-results",
    "title": "Assignment 8",
    "section": "Repeat step 3 using forward stepwise selection and backward stepwise selection and compare the results:",
    "text": "Repeat step 3 using forward stepwise selection and backward stepwise selection and compare the results:\n\n\nSubset selection object\nCall: regsubsets.formula(y ~ poly(X, 10, raw = T), data = data.frame(y, \n    X), nvmax = 10, method = \"forward\")\n10 Variables  (and intercept)\n                       Forced in Forced out\npoly(X, 10, raw = T)1      FALSE      FALSE\npoly(X, 10, raw = T)2      FALSE      FALSE\npoly(X, 10, raw = T)3      FALSE      FALSE\npoly(X, 10, raw = T)4      FALSE      FALSE\npoly(X, 10, raw = T)5      FALSE      FALSE\npoly(X, 10, raw = T)6      FALSE      FALSE\npoly(X, 10, raw = T)7      FALSE      FALSE\npoly(X, 10, raw = T)8      FALSE      FALSE\npoly(X, 10, raw = T)9      FALSE      FALSE\npoly(X, 10, raw = T)10     FALSE      FALSE\n1 subsets of each size up to 10\nSelection Algorithm: forward\n          poly(X, 10, raw = T)1 poly(X, 10, raw = T)2 poly(X, 10, raw = T)3\n1  ( 1 )  \"*\"                   \" \"                   \" \"                  \n2  ( 1 )  \"*\"                   \" \"                   \" \"                  \n3  ( 1 )  \"*\"                   \" \"                   \"*\"                  \n4  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n5  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n6  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n7  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n8  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n9  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n10  ( 1 ) \"*\"                   \"*\"                   \"*\"                  \n          poly(X, 10, raw = T)4 poly(X, 10, raw = T)5 poly(X, 10, raw = T)6\n1  ( 1 )  \" \"                   \" \"                   \" \"                  \n2  ( 1 )  \"*\"                   \" \"                   \" \"                  \n3  ( 1 )  \"*\"                   \" \"                   \" \"                  \n4  ( 1 )  \"*\"                   \" \"                   \" \"                  \n5  ( 1 )  \"*\"                   \"*\"                   \" \"                  \n6  ( 1 )  \"*\"                   \"*\"                   \" \"                  \n7  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n8  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n9  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n10  ( 1 ) \"*\"                   \"*\"                   \"*\"                  \n          poly(X, 10, raw = T)7 poly(X, 10, raw = T)8 poly(X, 10, raw = T)9\n1  ( 1 )  \" \"                   \" \"                   \" \"                  \n2  ( 1 )  \" \"                   \" \"                   \" \"                  \n3  ( 1 )  \" \"                   \" \"                   \" \"                  \n4  ( 1 )  \" \"                   \" \"                   \" \"                  \n5  ( 1 )  \" \"                   \" \"                   \" \"                  \n6  ( 1 )  \" \"                   \" \"                   \"*\"                  \n7  ( 1 )  \" \"                   \" \"                   \"*\"                  \n8  ( 1 )  \"*\"                   \" \"                   \"*\"                  \n9  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n10  ( 1 ) \"*\"                   \"*\"                   \"*\"                  \n          poly(X, 10, raw = T)10\n1  ( 1 )  \" \"                   \n2  ( 1 )  \" \"                   \n3  ( 1 )  \" \"                   \n4  ( 1 )  \" \"                   \n5  ( 1 )  \" \"                   \n6  ( 1 )  \" \"                   \n7  ( 1 )  \" \"                   \n8  ( 1 )  \" \"                   \n9  ( 1 )  \" \"                   \n10  ( 1 ) \"*\"                   \n\n\nSubset selection object\nCall: regsubsets.formula(y ~ poly(X, 10, raw = T), data = data.frame(y, \n    X), nvmax = 10, method = \"backward\")\n10 Variables  (and intercept)\n                       Forced in Forced out\npoly(X, 10, raw = T)1      FALSE      FALSE\npoly(X, 10, raw = T)2      FALSE      FALSE\npoly(X, 10, raw = T)3      FALSE      FALSE\npoly(X, 10, raw = T)4      FALSE      FALSE\npoly(X, 10, raw = T)5      FALSE      FALSE\npoly(X, 10, raw = T)6      FALSE      FALSE\npoly(X, 10, raw = T)7      FALSE      FALSE\npoly(X, 10, raw = T)8      FALSE      FALSE\npoly(X, 10, raw = T)9      FALSE      FALSE\npoly(X, 10, raw = T)10     FALSE      FALSE\n1 subsets of each size up to 10\nSelection Algorithm: backward\n          poly(X, 10, raw = T)1 poly(X, 10, raw = T)2 poly(X, 10, raw = T)3\n1  ( 1 )  \"*\"                   \" \"                   \" \"                  \n2  ( 1 )  \"*\"                   \" \"                   \" \"                  \n3  ( 1 )  \"*\"                   \" \"                   \" \"                  \n4  ( 1 )  \"*\"                   \" \"                   \" \"                  \n5  ( 1 )  \"*\"                   \" \"                   \" \"                  \n6  ( 1 )  \"*\"                   \" \"                   \" \"                  \n7  ( 1 )  \"*\"                   \" \"                   \" \"                  \n8  ( 1 )  \"*\"                   \" \"                   \" \"                  \n9  ( 1 )  \"*\"                   \"*\"                   \" \"                  \n10  ( 1 ) \"*\"                   \"*\"                   \"*\"                  \n          poly(X, 10, raw = T)4 poly(X, 10, raw = T)5 poly(X, 10, raw = T)6\n1  ( 1 )  \" \"                   \" \"                   \" \"                  \n2  ( 1 )  \"*\"                   \" \"                   \" \"                  \n3  ( 1 )  \"*\"                   \"*\"                   \" \"                  \n4  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n5  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n6  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n7  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n8  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n9  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n10  ( 1 ) \"*\"                   \"*\"                   \"*\"                  \n          poly(X, 10, raw = T)7 poly(X, 10, raw = T)8 poly(X, 10, raw = T)9\n1  ( 1 )  \" \"                   \" \"                   \" \"                  \n2  ( 1 )  \" \"                   \" \"                   \" \"                  \n3  ( 1 )  \" \"                   \" \"                   \" \"                  \n4  ( 1 )  \" \"                   \" \"                   \" \"                  \n5  ( 1 )  \" \"                   \"*\"                   \" \"                  \n6  ( 1 )  \" \"                   \"*\"                   \" \"                  \n7  ( 1 )  \"*\"                   \"*\"                   \" \"                  \n8  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n9  ( 1 )  \"*\"                   \"*\"                   \"*\"                  \n10  ( 1 ) \"*\"                   \"*\"                   \"*\"                  \n          poly(X, 10, raw = T)10\n1  ( 1 )  \" \"                   \n2  ( 1 )  \" \"                   \n3  ( 1 )  \" \"                   \n4  ( 1 )  \" \"                   \n5  ( 1 )  \" \"                   \n6  ( 1 )  \"*\"                   \n7  ( 1 )  \"*\"                   \n8  ( 1 )  \"*\"                   \n9  ( 1 )  \"*\"                   \n10  ( 1 ) \"*\"                   \n\n\nBest Model (Forward, BIC): 4 \n\n\nBest Model (Backward, BIC): 6"
  },
  {
    "objectID": "assignments/a8/a8.html#generate-predictor-x-and-noise-vector-𝜀along-with-response-vector-𝑦-and-plot-x-and-y",
    "href": "assignments/a8/a8.html#generate-predictor-x-and-noise-vector-𝜀along-with-response-vector-𝑦-and-plot-x-and-y",
    "title": "Assignment 8",
    "section": "Generate predictor X and noise vector 𝜀along with response vector 𝑦 and plot x and y:",
    "text": "Generate predictor X and noise vector 𝜀along with response vector 𝑦 and plot x and y:"
  },
  {
    "objectID": "assignments/taiwan-talk/taiwan.html",
    "href": "assignments/taiwan-talk/taiwan.html",
    "title": "Taiwan Talk - Cunningham",
    "section": "",
    "text": "# Load required libraries\nlibrary(tm)\n\nLoading required package: NLP\n\nlibrary(wordcloud)\n\nLoading required package: RColorBrewer\n\nlibrary(wordcloud2)\n\n# Read in the text from the provided content\ntext <- \"Taiwan, China, Nationalize, Policy-makers, Taiwan Strait, War, Soldiers, American, Geopolitics, Economics, Trade, Electronics, Supply-Chain, Semiconductors, OPEC, Oil, Saudi Arabia, Geopolitics, Military-bases, Island, Okinawa, War, Taiwan, China, Japan, Oil, Nationalistic, United States, China, Territory, Geopolitics, Aircraft, Trillion, Cost, Policy, Taiwan, Domestic Politics in China, CCP, Power, China, Power, China, Threat, Nationalistic, Xi, Power, Interest, CCP, Pressure, Taiwan, Taiwan, Claim, Imperialist, Claim, Claim, Independence, Diplomatic, Beijing, Fight, War, CCP, War, Military, Modernization, War, United States, Japan, Rising, Time, Military, Navy, Air Force, Opportunity, China, United States, Military, Industrial base, War, Rival, Power, Military, CCP, Tax, Companies, Goods, Public, Military, Taiwan Strait, China, Belligerent, China, Taiwan, Taiwan, United States, Status-Quo, Status-Quo, Fuzzy, De jure, Beijing, Domestic, Legitimacy, Deterring, United States, Taiwan, Security, Respond, Beijing, War, Win, Provoke, United States, Taiwan, War, Win, Taiwan, Nancy Pelosi, Taiwan, Military, Island, Provocative, White Paper, Media, White Paper, Journalist, Beijing, White Paper, 1993, 2000, 2022, Taiwan, White Paper, Xi Jinping, White Paper, 2000, Taiwan, One country two systems, Autonomy, Military, White Paper, Promise, Beijing, Compete, 2000, Force, 2000, 2000, Force, 2022, Force, Force, Provocation, Separatist, Red-line, Red-line, Anti-Secession Law, Reunification, Reunification, Reunification, War, Operation Causeway, Casualty, Amphibious, Military, Peacekeeping, Africa, Island, Offshore, Mao, Seizure, Taiwan, Debunk, Myths, Policy making, China, Opportunity, Population, Military, Military, Lean, Power, Xi, Taiwan, CCP, Xi, Elites, China, Xi, CCP, CCP, Timeline, Timeline, Succeed, 2049, Unification, Prerequisite, Rejuvenation, Vague, 2049, Taiwan, One country two systems, One country two systems, One country two systems, Timeline, 2025, 2027, centenary, Xi, CCP, Xi, Order, Military, centenary, 2049, Peace, Conflict, War, Conflict, Escalation, Miscalculation, Reckless, Taiwan, Asserting, Tensions, United States, Washington, Catastrophe, United States, Red-line, Taiwan, China, Intentional, Resolution, Politics, Taiwan, Xi Jinping, Taiwan, Power, DPP, DPP, KMT, KMT, KMT, KMT, Consensus, 92 consensus, One country two systems, KMT, DPP, William Lai, Taipei, Taiwan, Resolve, Objective, War, Tension, Objective, Status-Quo, Tension, Taiwan, KMT, Unification, Washington, DPP, Pro-Independence, KMT,KMT, Washington, CCP, DPP, Arms, Taiwan, United States, Arms, Washington, Taiwan, TECRO, TECRO, Nancy Pelosi, TECRO, China, United States, Nancy Pelosi, China, TECRO, Status-quo, Military, Escalation, Deterrent\""
  },
  {
    "objectID": "assignments/taiwan-talk/taiwan.html#creation-of-the-corpus-for-data-analysis",
    "href": "assignments/taiwan-talk/taiwan.html#creation-of-the-corpus-for-data-analysis",
    "title": "Taiwan Talk - Cunningham",
    "section": "Creation of the Corpus for data analysis",
    "text": "Creation of the Corpus for data analysis\n\n# Create a corpus from the text\ncorpus <- Corpus(VectorSource(text))\n\n# Convert to lowercase, remove punctuation, and remove numbers\ncorpus <- tm_map(corpus, content_transformer(tolower))\ncorpus <- tm_map(corpus, removePunctuation)\ncorpus <- tm_map(corpus, removeNumbers)\n\n# Convert the corpus to a term-document matrix\ntdm <- TermDocumentMatrix(corpus)\n\n# Convert the tdm to a matrix and calculate the frequency of each term\nm <- as.matrix(tdm)\nv <- sort(rowSums(m), decreasing=TRUE)\n\n# Create a dataframe of the most frequent terms and their frequencies\ndf <- data.frame(word = names(v), freq = v)"
  },
  {
    "objectID": "assignments/taiwan-talk/taiwan.html#creation-of-plots",
    "href": "assignments/taiwan-talk/taiwan.html#creation-of-plots",
    "title": "Taiwan Talk - Cunningham",
    "section": "Creation of plots",
    "text": "Creation of plots\n\n# Generate a word cloud\nwordcloud(words = df$word, freq = df$freq, scale=c(5,0.5), min.freq = 1, max.words=Inf, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, \"Dark2\"))\n\n# Load required libraries\nlibrary(tm)\nlibrary(ggplot2)\n\n\n\n# Create a corpus from the text\ncorpus <- Corpus(VectorSource(text))\n\n# Convert to lowercase, remove punctuation, and remove numbers\ncorpus <- tm_map(corpus, content_transformer(tolower))\ncorpus <- tm_map(corpus, removePunctuation)\ncorpus <- tm_map(corpus, removeNumbers)\n\n# Convert the corpus to a term-document matrix\ntdm <- TermDocumentMatrix(corpus)\n\n# Convert the tdm to a matrix and calculate the frequency of each term\nm <- as.matrix(tdm)\nv <- sort(rowSums(m), decreasing=TRUE)\n\n# Create a dataframe of the most frequent terms and their frequencies\ndf <- data.frame(word = names(v), freq = v)\n\n# Create a bar chart of the top 20 most frequent terms\nggplot(head(df, 20), aes(x=word, y=freq)) + geom_bar(stat=\"identity\", fill=\"dodgerblue\") + xlab(\"Words\") + ylab(\"Frequency\") + ggtitle(\"Most Frequent Words in Cunningham Talk\") + theme(plot.title = element_text(hjust = 0.5))"
  }
]